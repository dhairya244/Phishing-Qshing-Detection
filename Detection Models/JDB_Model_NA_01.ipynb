{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "gVYAz9zfSl_E",
        "outputId": "43cb300a-2d8b-454f-cebc-721fe6e32d4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c9d6c2de-2e14-4aac-b2c5-add594d38854\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>url_length</th>\n",
              "      <th>number_of_dots_in_url</th>\n",
              "      <th>having_repeated_digits_in_url</th>\n",
              "      <th>number_of_digits_in_url</th>\n",
              "      <th>number_of_special_char_in_url</th>\n",
              "      <th>number_of_hyphens_in_url</th>\n",
              "      <th>number_of_underline_in_url</th>\n",
              "      <th>number_of_slash_in_url</th>\n",
              "      <th>number_of_questionmark_in_url</th>\n",
              "      <th>...</th>\n",
              "      <th>having_digits_in_subdomain</th>\n",
              "      <th>number_of_digits_in_subdomain</th>\n",
              "      <th>having_repeated_digits_in_subdomain</th>\n",
              "      <th>having_path</th>\n",
              "      <th>path_length</th>\n",
              "      <th>having_query</th>\n",
              "      <th>having_fragment</th>\n",
              "      <th>having_anchor</th>\n",
              "      <th>entropy_of_url</th>\n",
              "      <th>entropy_of_domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.010412</td>\n",
              "      <td>2.751629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.089470</td>\n",
              "      <td>3.532573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.386016</td>\n",
              "      <td>3.344698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.221947</td>\n",
              "      <td>3.189898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.103538</td>\n",
              "      <td>2.952820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.136372</td>\n",
              "      <td>3.454822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.299706</td>\n",
              "      <td>3.101881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.366479</td>\n",
              "      <td>3.281036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.291266</td>\n",
              "      <td>3.854286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.362507</td>\n",
              "      <td>3.521641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9d6c2de-2e14-4aac-b2c5-add594d38854')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9d6c2de-2e14-4aac-b2c5-add594d38854 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9d6c2de-2e14-4aac-b2c5-add594d38854');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f8944835-f8d7-43fe-b2bd-e02fe3ce5b62\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8944835-f8d7-43fe-b2bd-e02fe3ce5b62')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f8944835-f8d7-43fe-b2bd-e02fe3ce5b62 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Type  url_length  number_of_dots_in_url  having_repeated_digits_in_url  \\\n",
              "0     0          37                      2                              0   \n",
              "1     1          70                      5                              0   \n",
              "2     0          42                      2                              0   \n",
              "3     0          46                      2                              0   \n",
              "4     0          51                      3                              0   \n",
              "5     0          51                      1                              0   \n",
              "6     0          86                      3                              0   \n",
              "7     1          64                      1                              0   \n",
              "8     0          54                      2                              0   \n",
              "9     0          44                      2                              0   \n",
              "\n",
              "   number_of_digits_in_url  number_of_special_char_in_url  \\\n",
              "0                        0                              8   \n",
              "1                        0                             12   \n",
              "2                        6                              8   \n",
              "3                        0                              7   \n",
              "4                        0                              9   \n",
              "5                        0                              9   \n",
              "6                        0                             14   \n",
              "7                        1                             10   \n",
              "8                        0                              8   \n",
              "9                        0                              8   \n",
              "\n",
              "   number_of_hyphens_in_url  number_of_underline_in_url  \\\n",
              "0                         0                           0   \n",
              "1                         0                           0   \n",
              "2                         0                           0   \n",
              "3                         0                           0   \n",
              "4                         0                           0   \n",
              "5                         2                           0   \n",
              "6                         6                           0   \n",
              "7                         0                           0   \n",
              "8                         0                           1   \n",
              "9                         1                           0   \n",
              "\n",
              "   number_of_slash_in_url  number_of_questionmark_in_url  ...  \\\n",
              "0                       5                              0  ...   \n",
              "1                       6                              0  ...   \n",
              "2                       3                              1  ...   \n",
              "3                       4                              0  ...   \n",
              "4                       5                              0  ...   \n",
              "5                       5                              0  ...   \n",
              "6                       4                              0  ...   \n",
              "7                       7                              0  ...   \n",
              "8                       4                              0  ...   \n",
              "9                       4                              0  ...   \n",
              "\n",
              "   having_digits_in_subdomain  number_of_digits_in_subdomain  \\\n",
              "0                           0                              0   \n",
              "1                           0                              0   \n",
              "2                           0                              0   \n",
              "3                           0                              0   \n",
              "4                           0                              0   \n",
              "5                           0                              0   \n",
              "6                           0                              0   \n",
              "7                           0                              0   \n",
              "8                           0                              0   \n",
              "9                           0                              0   \n",
              "\n",
              "   having_repeated_digits_in_subdomain  having_path  path_length  \\\n",
              "0                                    1            0            3   \n",
              "1                                    1            0            4   \n",
              "2                                    1            0            1   \n",
              "3                                    1            0            2   \n",
              "4                                    1            0            3   \n",
              "5                                    1            0            3   \n",
              "6                                    1            0            2   \n",
              "7                                    1            0            5   \n",
              "8                                    1            0            2   \n",
              "9                                    1            0            2   \n",
              "\n",
              "   having_query  having_fragment  having_anchor  entropy_of_url  \\\n",
              "0             0                0              0        4.010412   \n",
              "1             0                0              0        4.089470   \n",
              "2             1                0              0        4.386016   \n",
              "3             0                0              0        4.221947   \n",
              "4             0                0              0        4.103538   \n",
              "5             0                0              0        4.136372   \n",
              "6             0                0              0        4.299706   \n",
              "7             0                0              0        4.366479   \n",
              "8             0                0              0        4.291266   \n",
              "9             0                0              0        4.362507   \n",
              "\n",
              "   entropy_of_domain  \n",
              "0           2.751629  \n",
              "1           3.532573  \n",
              "2           3.344698  \n",
              "3           3.189898  \n",
              "4           2.952820  \n",
              "5           3.454822  \n",
              "6           3.101881  \n",
              "7           3.281036  \n",
              "8           3.854286  \n",
              "9           3.521641  \n",
              "\n",
              "[10 rows x 42 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Phishing_Dataset.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJDlEj6VXyz",
        "outputId": "b1d486b6-70a7-4f84-e2ce-9e6590c74cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Shape of Dataset: (247950, 42)\n",
            "Columns: Index(['Type', 'url_length', 'number_of_dots_in_url',\n",
            "       'having_repeated_digits_in_url', 'number_of_digits_in_url',\n",
            "       'number_of_special_char_in_url', 'number_of_hyphens_in_url',\n",
            "       'number_of_underline_in_url', 'number_of_slash_in_url',\n",
            "       'number_of_questionmark_in_url', 'number_of_equal_in_url',\n",
            "       'number_of_at_in_url', 'number_of_dollar_in_url',\n",
            "       'number_of_exclamation_in_url', 'number_of_hashtag_in_url',\n",
            "       'number_of_percent_in_url', 'domain_length', 'number_of_dots_in_domain',\n",
            "       'number_of_hyphens_in_domain', 'having_special_characters_in_domain',\n",
            "       'number_of_special_characters_in_domain', 'having_digits_in_domain',\n",
            "       'number_of_digits_in_domain', 'having_repeated_digits_in_domain',\n",
            "       'number_of_subdomains', 'having_dot_in_subdomain',\n",
            "       'having_hyphen_in_subdomain', 'average_subdomain_length',\n",
            "       'average_number_of_dots_in_subdomain',\n",
            "       'average_number_of_hyphens_in_subdomain',\n",
            "       'having_special_characters_in_subdomain',\n",
            "       'number_of_special_characters_in_subdomain',\n",
            "       'having_digits_in_subdomain', 'number_of_digits_in_subdomain',\n",
            "       'having_repeated_digits_in_subdomain', 'having_path', 'path_length',\n",
            "       'having_query', 'having_fragment', 'having_anchor', 'entropy_of_url',\n",
            "       'entropy_of_domain'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Data Overview\n",
        "print(\"Initial Shape of Dataset:\", df.shape)\n",
        "print(\"Columns:\", df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "078CoZtcVcH2",
        "outputId": "a50faaaf-427c-4f47-878c-c8dc6e142ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after removing duplicates: (129778, 42)\n",
            "Missing values handled\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 2: Removing Duplicate URLs\n",
        "df_cleaned = df.drop_duplicates()\n",
        "print(\"Shape after removing duplicates:\", df_cleaned.shape)\n",
        "\n",
        "# Step 3: Handling Missing Values\n",
        "# Replace missing values with median or mean, or drop columns if necessary\n",
        "df_cleaned = df_cleaned.fillna(df_cleaned.median())\n",
        "print(\"Missing values handled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1okelpxsVfcc",
        "outputId": "0aa23861-ca3f-4e68-fc2a-84f843ab7060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after outlier removal: (120122, 42)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 4: Outlier Detection and Removal\n",
        "# Assuming `url_length` and `entropy_of_url` could have potential outliers\n",
        "def remove_outliers(df, column):\n",
        "    # Define IQR (Interquartile range)\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    # Filter out outliers\n",
        "    return df[~((df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR)))]\n",
        "\n",
        "\n",
        "# Removing outliers based on `url_length` and `entropy_of_url`\n",
        "df_cleaned = remove_outliers(df_cleaned, 'url_length')\n",
        "df_cleaned = remove_outliers(df_cleaned, 'entropy_of_url')\n",
        "print(\"Shape after outlier removal:\", df_cleaned.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-3v-6KMVkc-",
        "outputId": "57304ec3-fc89-4480-e732-f29a150ffd67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data scaling completed\n",
            "Final Shape of Dataset: (120122, 42)\n",
            "First few rows of the final dataset:\n",
            "   Type  url_length  number_of_dots_in_url  having_repeated_digits_in_url  \\\n",
            "0     0   -0.856990              -0.551060                              0   \n",
            "1     1    0.744539               1.684308                              0   \n",
            "2     0   -0.614334              -0.551060                              0   \n",
            "3     0   -0.420209              -0.551060                              0   \n",
            "4     0   -0.177554               0.194062                              0   \n",
            "\n",
            "   number_of_digits_in_url  number_of_special_char_in_url  \\\n",
            "0                        0                              8   \n",
            "1                        0                             12   \n",
            "2                        6                              8   \n",
            "3                        0                              7   \n",
            "4                        0                              9   \n",
            "\n",
            "   number_of_hyphens_in_url  number_of_underline_in_url  \\\n",
            "0                         0                           0   \n",
            "1                         0                           0   \n",
            "2                         0                           0   \n",
            "3                         0                           0   \n",
            "4                         0                           0   \n",
            "\n",
            "   number_of_slash_in_url  number_of_questionmark_in_url  ...  \\\n",
            "0                       5                              0  ...   \n",
            "1                       6                              0  ...   \n",
            "2                       3                              1  ...   \n",
            "3                       4                              0  ...   \n",
            "4                       5                              0  ...   \n",
            "\n",
            "   having_digits_in_subdomain  number_of_digits_in_subdomain  \\\n",
            "0                           0                              0   \n",
            "1                           0                              0   \n",
            "2                           0                              0   \n",
            "3                           0                              0   \n",
            "4                           0                              0   \n",
            "\n",
            "   having_repeated_digits_in_subdomain  having_path  path_length  \\\n",
            "0                                    1            0            3   \n",
            "1                                    1            0            4   \n",
            "2                                    1            0            1   \n",
            "3                                    1            0            2   \n",
            "4                                    1            0            3   \n",
            "\n",
            "   having_query  having_fragment  having_anchor  entropy_of_url  \\\n",
            "0             0                0              0       -0.803340   \n",
            "1             0                0              0       -0.515449   \n",
            "2             1                0              0        0.564429   \n",
            "3             0                0              0       -0.033033   \n",
            "4             0                0              0       -0.464221   \n",
            "\n",
            "   entropy_of_domain  \n",
            "0          -1.781026  \n",
            "1           0.370554  \n",
            "2          -0.147061  \n",
            "3          -0.573551  \n",
            "4          -1.226726  \n",
            "\n",
            "[5 rows x 42 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "# Step 5: Scaling the Features (optional for certain algorithms)\n",
        "# Normalize or scale numerical features if needed\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# List of features to be scaled\n",
        "columns_to_scale = ['url_length', 'number_of_dots_in_url', 'entropy_of_url', 'entropy_of_domain']\n",
        "\n",
        "# Apply scaling\n",
        "df_cleaned[columns_to_scale] = scaler.fit_transform(df_cleaned[columns_to_scale])\n",
        "print(\"Data scaling completed\")\n",
        "\n",
        "# Final Step: Final Data Overview\n",
        "print(\"Final Shape of Dataset:\", df_cleaned.shape)\n",
        "print(\"First few rows of the final dataset:\")\n",
        "print(df_cleaned.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce-vcu5DWsY2"
      },
      "outputs": [],
      "source": [
        "# Saving the cleaned dataset\n",
        "df_cleaned.to_csv('cleaned_dataset.csv', index=False)\n",
        "print(\"Cleaned dataset saved as 'cleaned_dataset.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVWWrdJnozQB"
      },
      "source": [
        "Start the process from here,\n",
        "- **cleaned_dataset:** Consists of a complete cleaned dataset which has filtered the data with respect to model trainning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHSnnMWAiayO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Step 1: Split dataset into features and target\n",
        "X = df.drop(columns=['Type'])  # Features\n",
        "y = df['Type']  # Target variable (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAW60n57ijSS"
      },
      "outputs": [],
      "source": [
        "# Step 2: Train-test split (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train a Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict on test data\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NtRtkmOqlUZ"
      },
      "source": [
        "# Accuracy metrics of the trainned model Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp41SWWdiouT",
        "outputId": "947b8aa6-62a4-4e5b-86eb-cb57f42f727c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9673522887678968\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     25668\n",
            "           1       0.97      0.96      0.97     23922\n",
            "\n",
            "    accuracy                           0.97     49590\n",
            "   macro avg       0.97      0.97      0.97     49590\n",
            "weighted avg       0.97      0.97      0.97     49590\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[25052   616]\n",
            " [ 1003 22919]]\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL4z4RPGvdiX"
      },
      "source": [
        "2 Parameter tests done:\n",
        "1. Original Deep Hyperparameter Testing\n",
        "2. Shortemed Hyperparameter Testing: More Accurate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5it-Yz_Zkxj0",
        "outputId": "9de1032d-243b-4354-d3df-c940b394621a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}\n",
            "Best hyperparameters saved to 'Final_best_hyperparameters.json'\n"
          ]
        }
      ],
      "source": [
        "#This is original hyperparameter but is paused for now, will executer a shorter one\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Assuming X_train and y_train are already defined as the training data\n",
        "# Step 3: Set up hyperparameter grid for RandomForest\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 200, 50),  # Instead of a wide range, we test a few values\n",
        "    'max_depth': [10, 20, None],  # Reduced options for max depth\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Step 4: Set up the RandomizedSearchCV (n_iter=50 means it will try 50 different combinations)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=50,\n",
        "                                   cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
        "\n",
        "# Step 5: Fit the random search to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Output the best parameters\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "\n",
        "# Step 7: Convert the best parameters to standard Python types\n",
        "best_params = {key: int(value) if isinstance(value, np.integer) else value for key, value in random_search.best_params_.items()}\n",
        "\n",
        "# Step 8: Write the parameters to a JSON file\n",
        "with open('Final_best_hyperparameters.json', 'w') as json_file:\n",
        "    json.dump(best_params, json_file)\n",
        "\n",
        "print(\"Best hyperparameters saved to 'Final_best_hyperparameters.json'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgeyaDRWwNSb"
      },
      "source": [
        "**Shortened Hyperparameter Testing:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUNX_6WYaEM9",
        "outputId": "dd5da1df-fd78-4a79-8a47-220eda8f81b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rHyperparameter Search Progress:   0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "Hyperparameter Search Progress:  10%|█         | 1/10 [01:39<14:53, 99.24s/it, Elapsed=99.24 sec, Remaining=893.13 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  20%|██        | 2/10 [03:15<13:00, 97.58s/it, Elapsed=195.66 sec, Remaining=771.32 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  30%|███       | 3/10 [04:51<11:17, 96.77s/it, Elapsed=291.46 sec, Remaining=670.56 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  40%|████      | 4/10 [06:27<09:39, 96.67s/it, Elapsed=387.97 sec, Remaining=579.02 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  50%|█████     | 5/10 [08:03<08:01, 96.26s/it, Elapsed=483.51 sec, Remaining=477.66 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  60%|██████    | 6/10 [09:38<06:23, 95.91s/it, Elapsed=578.74 sec, Remaining=380.92 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  70%|███████   | 7/10 [11:15<04:48, 96.04s/it, Elapsed=675.05 sec, Remaining=288.91 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  80%|████████  | 8/10 [12:49<03:11, 95.54s/it, Elapsed=769.52 sec, Remaining=188.91 sec]/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress:  90%|█████████ | 9/10 [14:24<01:35, 95.37s/it, Elapsed=864.52 sec, Remaining=95.00 sec] /usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "Hyperparameter Search Progress: 100%|██████████| 10/10 [15:59<00:00, 95.97s/it, Elapsed=959.73 sec, Remaining=0.00 sec]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 100, 'max_depth': None}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "# Assuming X_train and y_train are already defined as the training data\n",
        "\n",
        "# Step 1: Set up hyperparameter grid for RandomForest\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100],  # Reduced range of n_estimators\n",
        "    'max_depth': [10, None],    # Only test two values for max depth\n",
        "}\n",
        "\n",
        "# Step 2: Set up the RandomizedSearchCV with fewer iterations (e.g., 10 iterations)\n",
        "n_iter_search = 10  # Limiting the number of combinations to speed up\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search, cv=3, n_jobs=-1, random_state=42, verbose=0)\n",
        "\n",
        "# Step 3: Track progress and expected time to complete\n",
        "# Initialize progress bar\n",
        "pbar = tqdm(total=n_iter_search, desc=\"Hyperparameter Search Progress\")\n",
        "\n",
        "# Function to manually track progress\n",
        "start_time = time.time()  # To calculate the elapsed time\n",
        "\n",
        "# Fit with manual tracking\n",
        "for i in range(n_iter_search):\n",
        "    start_iter = time.time()  # Start time for the iteration\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate elapsed time per iteration\n",
        "    iter_time = time.time() - start_iter\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Estimate remaining time\n",
        "    remaining_iters = n_iter_search - (i + 1)\n",
        "    estimated_time_remaining = remaining_iters * iter_time\n",
        "\n",
        "    # Update progress bar\n",
        "    pbar.update(1)\n",
        "    pbar.set_postfix({\n",
        "        'Elapsed': f\"{elapsed_time:.2f} sec\",\n",
        "        'Remaining': f\"{estimated_time_remaining:.2f} sec\"\n",
        "    })\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "# Step 4: Output the best parameters\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "315-nRwdihkb",
        "outputId": "353ae45b-2aee-4014-b77c-7e6439339a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 100, 'max_depth': None}\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Output the best parameters\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPrmCts3jHmI",
        "outputId": "1dc2b35f-beac-425b-cbff-75a6b4a28064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters saved to 'Shortened_best_hyperparameters.json'\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Save best hyperparameters to a JSON file\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Write the parameters to a JSON file\n",
        "with open('Shortened_best_hyperparameters.json', 'w') as json_file:\n",
        "    json.dump(best_params, json_file)\n",
        "\n",
        "print(\"Best hyperparameters saved to 'Shortened_best_hyperparameters.json'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4X9LS-6wbAZ"
      },
      "source": [
        "Loading Shortened hyperparameter and monitoring their accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTpWzjfmuYsT",
        "outputId": "f7656aea-af68-4704-d255-857174d9acce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded best hyperparameters: {'n_estimators': 100, 'max_depth': None}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the best hyperparameters from the JSON file\n",
        "with open('Shortened_best_hyperparameters.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Print the loaded hyperparameters\n",
        "print(\"Loaded best hyperparameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoFqkOCHjOhd",
        "outputId": "9a2f7ac9-62f3-4334-9aa3-3cb666c1887f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9673522887678968\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     25668\n",
            "           1       0.97      0.96      0.97     23922\n",
            "\n",
            "    accuracy                           0.97     49590\n",
            "   macro avg       0.97      0.97      0.97     49590\n",
            "weighted avg       0.97      0.97      0.97     49590\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[25052   616]\n",
            " [ 1003 22919]]\n"
          ]
        }
      ],
      "source": [
        "# Train the Random Forest model with the best parameters\n",
        "best_rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Display the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCtunYQBjwFg",
        "outputId": "15140b74-2716-466b-db47-cb26713a9ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained model saved to 'shortened_best_random_forest_model.pkl'\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained Random Forest model to a file\n",
        "with open('Shortened_best_random_forest_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(best_rf_model, model_file)\n",
        "\n",
        "print(\"Trained model saved to 'shortened_best_random_forest_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qAiCMQLwktNr"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "import math\n",
        "\n",
        "# Function to calculate entropy of a string (used for URL and domain entropy)\n",
        "def calculate_entropy(s):\n",
        "    prob = [float(s.count(c)) / len(s) for c in dict.fromkeys(list(s))]\n",
        "    entropy = -sum([p * math.log2(p) for p in prob])\n",
        "    return entropy\n",
        "\n",
        "# Feature extraction function for dynamically entered URL\n",
        "def extract_features(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    features = []\n",
        "\n",
        "    # Extract the domain from the URL\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Extract subdomain from the domain\n",
        "    subdomain = domain.split('.')[0] if '.' in domain else domain\n",
        "\n",
        "    # Feature 1: url_length\n",
        "    url_length = len(url)\n",
        "\n",
        "    # Feature 2: number_of_dots_in_url\n",
        "    number_of_dots_in_url = url.count('.')\n",
        "\n",
        "    # Feature 3: having_repeated_digits_in_url\n",
        "    having_repeated_digits_in_url = 1 if any(str(i) * 2 in url for i in range(10)) else 0\n",
        "\n",
        "    # Feature 4: number_of_digits_in_url\n",
        "    number_of_digits_in_url = sum(c.isdigit() for c in url)\n",
        "\n",
        "    # Feature 5: number_of_special_char_in_url\n",
        "    special_chars = \"!@#$%^&*()_+=-{}[]|\\\\:;\\\"'<>,.?/~`\"\n",
        "    number_of_special_char_in_url = sum(c in special_chars for c in url)\n",
        "\n",
        "    # Feature 6: number_of_hyphens_in_url\n",
        "    number_of_hyphens_in_url = url.count('-')\n",
        "\n",
        "    # Feature 7: number_of_underline_in_url\n",
        "    number_of_underline_in_url = url.count('_')\n",
        "\n",
        "    # Feature 8: number_of_slash_in_url\n",
        "    number_of_slash_in_url = url.count('/')\n",
        "\n",
        "    # Feature 9: number_of_questionmark_in_url\n",
        "    number_of_questionmark_in_url = url.count('?')\n",
        "\n",
        "    # Feature 10: having_digits_in_subdomain\n",
        "    having_digits_in_subdomain = 1 if any(char.isdigit() for char in subdomain) else 0\n",
        "\n",
        "    # Feature 11: number_of_digits_in_subdomain\n",
        "    number_of_digits_in_subdomain = sum(char.isdigit() for char in subdomain)\n",
        "\n",
        "    # Feature 12: having_repeated_digits_in_subdomain\n",
        "    having_repeated_digits_in_subdomain = 1 if any(str(i) * 2 in subdomain for i in range(10)) else 0\n",
        "\n",
        "    # Feature 13: having_path\n",
        "    having_path = 1 if parsed_url.path else 0\n",
        "\n",
        "    # Feature 14: path_length\n",
        "    path_length = len(parsed_url.path)\n",
        "\n",
        "    # Feature 15: having_query\n",
        "    having_query = 1 if parsed_url.query else 0\n",
        "\n",
        "    # Feature 16: having_fragment\n",
        "    having_fragment = 1 if parsed_url.fragment else 0\n",
        "\n",
        "    # Feature 17: having_anchor (simplified to check if '#' is present)\n",
        "    having_anchor = 1 if '#' in url else 0\n",
        "\n",
        "    # Feature 18: entropy_of_url\n",
        "    entropy_of_url = calculate_entropy(url)\n",
        "\n",
        "    # Feature 19: entropy_of_domain\n",
        "    entropy_of_domain = calculate_entropy(domain)\n",
        "\n",
        "    # Additional features based on URL structure\n",
        "    # Feature 20: domain_length\n",
        "    domain_length = len(domain)\n",
        "\n",
        "    # Feature 21: number_of_dots_in_domain\n",
        "    number_of_dots_in_domain = domain.count('.')\n",
        "\n",
        "    # Feature 22: number_of_hyphens_in_domain\n",
        "    number_of_hyphens_in_domain = domain.count('-')\n",
        "\n",
        "    # Feature 23: number_of_digits_in_domain\n",
        "    number_of_digits_in_domain = sum(char.isdigit() for char in domain)\n",
        "\n",
        "    # Feature 24: having_digits_in_domain\n",
        "    having_digits_in_domain = 1 if any(char.isdigit() for char in domain) else 0\n",
        "\n",
        "    # Feature 25: having_special_characters_in_domain\n",
        "    having_special_characters_in_domain = 1 if any(c in special_chars for c in domain) else 0\n",
        "\n",
        "    # Feature 26: number_of_special_characters_in_domain\n",
        "    number_of_special_characters_in_domain = sum(c in special_chars for c in domain)\n",
        "\n",
        "    # Feature 27: number_of_subdomains (split domain into subdomain parts)\n",
        "    number_of_subdomains = domain.count('.')\n",
        "\n",
        "    # Feature 28: number_of_equal_in_url\n",
        "    number_of_equal_in_url = url.count('=')\n",
        "\n",
        "    # Feature 29: number_of_at_in_url\n",
        "    number_of_at_in_url = url.count('@')\n",
        "\n",
        "    # Feature 30: number_of_percent_in_url\n",
        "    number_of_percent_in_url = url.count('%')\n",
        "\n",
        "    # Feature 31: number_of_hashtag_in_url\n",
        "    number_of_hashtag_in_url = url.count('#')\n",
        "\n",
        "    # Feature 32: number_of_exclamation_in_url\n",
        "    number_of_exclamation_in_url = url.count('!')\n",
        "\n",
        "    # Feature 33: number_of_dollar_in_url\n",
        "    number_of_dollar_in_url = url.count('$')\n",
        "\n",
        "    # Feature 34: number_of_hyphens_in_subdomain\n",
        "    number_of_hyphens_in_subdomain = subdomain.count('-')\n",
        "\n",
        "    # Feature 35: number_of_special_characters_in_subdomain\n",
        "    number_of_special_characters_in_subdomain = sum(c in special_chars for c in subdomain)\n",
        "\n",
        "    # Feature 36: having_special_characters_in_subdomain\n",
        "    having_special_characters_in_subdomain = 1 if any(c in special_chars for c in subdomain) else 0\n",
        "\n",
        "    # Feature 37: having_dot_in_subdomain\n",
        "    having_dot_in_subdomain = 1 if '.' in subdomain else 0\n",
        "\n",
        "    # Feature 38: number_of_underline_in_subdomain\n",
        "    number_of_underline_in_subdomain = subdomain.count('_')\n",
        "\n",
        "    # Feature 39: having_hyphen_in_subdomain\n",
        "    having_hyphen_in_subdomain = 1 if '-' in subdomain else 0\n",
        "\n",
        "    # Feature 40: number_of_slash_in_subdomain\n",
        "    number_of_slash_in_subdomain = subdomain.count('/')\n",
        "\n",
        "    # Feature 41: having_repeated_digits_in_domain\n",
        "    having_repeated_digits_in_domain = 1 if any(str(i) * 2 in domain for i in range(10)) else 0\n",
        "\n",
        "    # Append all features to the list\n",
        "    features = [\n",
        "        url_length, number_of_dots_in_url, having_repeated_digits_in_url, number_of_digits_in_url,\n",
        "        number_of_special_char_in_url, number_of_hyphens_in_url, number_of_underline_in_url,\n",
        "        number_of_slash_in_url, number_of_questionmark_in_url, having_digits_in_subdomain,\n",
        "        number_of_digits_in_subdomain, having_repeated_digits_in_subdomain, having_path,\n",
        "        path_length, having_query, having_fragment, having_anchor, entropy_of_url, entropy_of_domain,\n",
        "        domain_length, number_of_dots_in_domain, number_of_hyphens_in_domain, number_of_digits_in_domain,\n",
        "        having_digits_in_domain, having_special_characters_in_domain, number_of_special_characters_in_domain,\n",
        "        number_of_subdomains, number_of_equal_in_url, number_of_at_in_url, number_of_percent_in_url,\n",
        "        number_of_hashtag_in_url, number_of_exclamation_in_url, number_of_dollar_in_url,\n",
        "        number_of_hyphens_in_subdomain, number_of_special_characters_in_subdomain,\n",
        "        having_special_characters_in_subdomain, having_dot_in_subdomain, number_of_underline_in_subdomain,\n",
        "        having_hyphen_in_subdomain, number_of_slash_in_subdomain, having_repeated_digits_in_domain\n",
        "    ]\n",
        "\n",
        "    # Return features as a 2D array for model prediction\n",
        "    return np.array(features).reshape(1, -1)\n",
        "\n",
        "# Load the trained model\n",
        "with open('Shortened_best_random_forest_model.pkl', 'rb') as model_file:\n",
        "    model = pickle.load(model_file)\n",
        "\n",
        "# Input URL dynamically\n",
        "url = input(\"Enter a URL to check if it's phishy or legitimate: \")\n",
        "\n",
        "# Check the number of features expected by the model\n",
        "print(f\"Model expects {model.n_features_in_} features.\")\n",
        "\n",
        "# Extract features from the URL\n",
        "url_features = extract_features(url)\n",
        "\n",
        "# Check the number of features extracted\n",
        "print(f\"Extracted {url_features.shape[1]} features.\")\n",
        "\n",
        "# Predict using the model\n",
        "prediction = model.predict(url_features)\n",
        "\n",
        "# Output result\n",
        "if prediction == 1:\n",
        "    print(f\"The URL '{url}' is predicted as **Phishy**.\")\n",
        "else:\n",
        "    print(f\"The URL '{url}' is predicted as **Legitimate**.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAuKc-1xxXQk"
      },
      "source": [
        "Similarly, Working on the Original Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJMCXW4sx_SB",
        "outputId": "b0b0d4a3-6446-45f8-9ddd-397aa23d03c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded best hyperparameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the best hyperparameters from the JSON file\n",
        "with open('Final_Original_best_hyperparameters.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Print the loaded hyperparameters\n",
        "print(\"Loaded best hyperparameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JKlZqsQx_SC",
        "outputId": "5b33f128-64a3-46d8-f747-fdd9688618fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9673522887678968\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     25668\n",
            "           1       0.97      0.96      0.97     23922\n",
            "\n",
            "    accuracy                           0.97     49590\n",
            "   macro avg       0.97      0.97      0.97     49590\n",
            "weighted avg       0.97      0.97      0.97     49590\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[25052   616]\n",
            " [ 1003 22919]]\n"
          ]
        }
      ],
      "source": [
        "# Train the Random Forest model with the best parameters\n",
        "best_rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Display the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPiR3nN8x_SD",
        "outputId": "70732e15-693d-4b61-f5a7-e7b92bec9238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained model saved to 'shortened_best_random_forest_model.pkl'\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained Random Forest model to a file\n",
        "with open('Original_best_random_forest_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(best_rf_model, model_file)\n",
        "\n",
        "print(\"Trained model saved to 'shortened_best_random_forest_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXvQkIy-x_SD",
        "outputId": "c7aed5eb-be4a-4e24-f38a-d4511d4d310c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a URL to check if it's phishy or legitimate: https://app.slack.com/client/T07AE67FCFM/C07AY99EQ6M\n",
            "Model expects 41 features.\n",
            "Extracted 41 features.\n",
            "The URL 'https://app.slack.com/client/T07AE67FCFM/C07AY99EQ6M' is predicted as **Legitimate**.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "import math\n",
        "\n",
        "# Function to calculate entropy of a string (used for URL and domain entropy)\n",
        "def calculate_entropy(s):\n",
        "    prob = [float(s.count(c)) / len(s) for c in dict.fromkeys(list(s))]\n",
        "    entropy = -sum([p * math.log2(p) for p in prob])\n",
        "    return entropy\n",
        "\n",
        "# Feature extraction function for dynamically entered URL\n",
        "def extract_features(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    features = []\n",
        "\n",
        "    # Extract the domain from the URL\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Extract subdomain from the domain\n",
        "    subdomain = domain.split('.')[0] if '.' in domain else domain\n",
        "\n",
        "    # Feature 1: url_length\n",
        "    url_length = len(url)\n",
        "\n",
        "    # Feature 2: number_of_dots_in_url\n",
        "    number_of_dots_in_url = url.count('.')\n",
        "\n",
        "    # Feature 3: having_repeated_digits_in_url\n",
        "    having_repeated_digits_in_url = 1 if any(str(i) * 2 in url for i in range(10)) else 0\n",
        "\n",
        "    # Feature 4: number_of_digits_in_url\n",
        "    number_of_digits_in_url = sum(c.isdigit() for c in url)\n",
        "\n",
        "    # Feature 5: number_of_special_char_in_url\n",
        "    special_chars = \"!@#$%^&*()_+=-{}[]|\\\\:;\\\"'<>,.?/~`\"\n",
        "    number_of_special_char_in_url = sum(c in special_chars for c in url)\n",
        "\n",
        "    # Feature 6: number_of_hyphens_in_url\n",
        "    number_of_hyphens_in_url = url.count('-')\n",
        "\n",
        "    # Feature 7: number_of_underline_in_url\n",
        "    number_of_underline_in_url = url.count('_')\n",
        "\n",
        "    # Feature 8: number_of_slash_in_url\n",
        "    number_of_slash_in_url = url.count('/')\n",
        "\n",
        "    # Feature 9: number_of_questionmark_in_url\n",
        "    number_of_questionmark_in_url = url.count('?')\n",
        "\n",
        "    # Feature 10: having_digits_in_subdomain\n",
        "    having_digits_in_subdomain = 1 if any(char.isdigit() for char in subdomain) else 0\n",
        "\n",
        "    # Feature 11: number_of_digits_in_subdomain\n",
        "    number_of_digits_in_subdomain = sum(char.isdigit() for char in subdomain)\n",
        "\n",
        "    # Feature 12: having_repeated_digits_in_subdomain\n",
        "    having_repeated_digits_in_subdomain = 1 if any(str(i) * 2 in subdomain for i in range(10)) else 0\n",
        "\n",
        "    # Feature 13: having_path\n",
        "    having_path = 1 if parsed_url.path else 0\n",
        "\n",
        "    # Feature 14: path_length\n",
        "    path_length = len(parsed_url.path)\n",
        "\n",
        "    # Feature 15: having_query\n",
        "    having_query = 1 if parsed_url.query else 0\n",
        "\n",
        "    # Feature 16: having_fragment\n",
        "    having_fragment = 1 if parsed_url.fragment else 0\n",
        "\n",
        "    # Feature 17: having_anchor (simplified to check if '#' is present)\n",
        "    having_anchor = 1 if '#' in url else 0\n",
        "\n",
        "    # Feature 18: entropy_of_url\n",
        "    entropy_of_url = calculate_entropy(url)\n",
        "\n",
        "    # Feature 19: entropy_of_domain\n",
        "    entropy_of_domain = calculate_entropy(domain)\n",
        "\n",
        "    # Additional features based on URL structure\n",
        "    # Feature 20: domain_length\n",
        "    domain_length = len(domain)\n",
        "\n",
        "    # Feature 21: number_of_dots_in_domain\n",
        "    number_of_dots_in_domain = domain.count('.')\n",
        "\n",
        "    # Feature 22: number_of_hyphens_in_domain\n",
        "    number_of_hyphens_in_domain = domain.count('-')\n",
        "\n",
        "    # Feature 23: number_of_digits_in_domain\n",
        "    number_of_digits_in_domain = sum(char.isdigit() for char in domain)\n",
        "\n",
        "    # Feature 24: having_digits_in_domain\n",
        "    having_digits_in_domain = 1 if any(char.isdigit() for char in domain) else 0\n",
        "\n",
        "    # Feature 25: having_special_characters_in_domain\n",
        "    having_special_characters_in_domain = 1 if any(c in special_chars for c in domain) else 0\n",
        "\n",
        "    # Feature 26: number_of_special_characters_in_domain\n",
        "    number_of_special_characters_in_domain = sum(c in special_chars for c in domain)\n",
        "\n",
        "    # Feature 27: number_of_subdomains (split domain into subdomain parts)\n",
        "    number_of_subdomains = domain.count('.')\n",
        "\n",
        "    # Feature 28: number_of_equal_in_url\n",
        "    number_of_equal_in_url = url.count('=')\n",
        "\n",
        "    # Feature 29: number_of_at_in_url\n",
        "    number_of_at_in_url = url.count('@')\n",
        "\n",
        "    # Feature 30: number_of_percent_in_url\n",
        "    number_of_percent_in_url = url.count('%')\n",
        "\n",
        "    # Feature 31: number_of_hashtag_in_url\n",
        "    number_of_hashtag_in_url = url.count('#')\n",
        "\n",
        "    # Feature 32: number_of_exclamation_in_url\n",
        "    number_of_exclamation_in_url = url.count('!')\n",
        "\n",
        "    # Feature 33: number_of_dollar_in_url\n",
        "    number_of_dollar_in_url = url.count('$')\n",
        "\n",
        "    # Feature 34: number_of_hyphens_in_subdomain\n",
        "    number_of_hyphens_in_subdomain = subdomain.count('-')\n",
        "\n",
        "    # Feature 35: number_of_special_characters_in_subdomain\n",
        "    number_of_special_characters_in_subdomain = sum(c in special_chars for c in subdomain)\n",
        "\n",
        "    # Feature 36: having_special_characters_in_subdomain\n",
        "    having_special_characters_in_subdomain = 1 if any(c in special_chars for c in subdomain) else 0\n",
        "\n",
        "    # Feature 37: having_dot_in_subdomain\n",
        "    having_dot_in_subdomain = 1 if '.' in subdomain else 0\n",
        "\n",
        "    # Feature 38: number_of_underline_in_subdomain\n",
        "    number_of_underline_in_subdomain = subdomain.count('_')\n",
        "\n",
        "    # Feature 39: having_hyphen_in_subdomain\n",
        "    having_hyphen_in_subdomain = 1 if '-' in subdomain else 0\n",
        "\n",
        "    # Feature 40: number_of_slash_in_subdomain\n",
        "    number_of_slash_in_subdomain = subdomain.count('/')\n",
        "\n",
        "    # Feature 41: having_repeated_digits_in_domain\n",
        "    having_repeated_digits_in_domain = 1 if any(str(i) * 2 in domain for i in range(10)) else 0\n",
        "\n",
        "    # Append all features to the list\n",
        "    features = [\n",
        "        url_length, number_of_dots_in_url, having_repeated_digits_in_url, number_of_digits_in_url,\n",
        "        number_of_special_char_in_url, number_of_hyphens_in_url, number_of_underline_in_url,\n",
        "        number_of_slash_in_url, number_of_questionmark_in_url, having_digits_in_subdomain,\n",
        "        number_of_digits_in_subdomain, having_repeated_digits_in_subdomain, having_path,\n",
        "        path_length, having_query, having_fragment, having_anchor, entropy_of_url, entropy_of_domain,\n",
        "        domain_length, number_of_dots_in_domain, number_of_hyphens_in_domain, number_of_digits_in_domain,\n",
        "        having_digits_in_domain, having_special_characters_in_domain, number_of_special_characters_in_domain,\n",
        "        number_of_subdomains, number_of_equal_in_url, number_of_at_in_url, number_of_percent_in_url,\n",
        "        number_of_hashtag_in_url, number_of_exclamation_in_url, number_of_dollar_in_url,\n",
        "        number_of_hyphens_in_subdomain, number_of_special_characters_in_subdomain,\n",
        "        having_special_characters_in_subdomain, having_dot_in_subdomain, number_of_underline_in_subdomain,\n",
        "        having_hyphen_in_subdomain, number_of_slash_in_subdomain, having_repeated_digits_in_domain\n",
        "    ]\n",
        "\n",
        "    # Return features as a 2D array for model prediction\n",
        "    return np.array(features).reshape(1, -1)\n",
        "\n",
        "# Load the trained model\n",
        "with open('Shortened_best_random_forest_model.pkl', 'rb') as model_file:\n",
        "    model = pickle.load(model_file)\n",
        "\n",
        "# Input URL dynamically\n",
        "url = input(\"Enter a URL to check if it's phishy or legitimate: \")\n",
        "\n",
        "# Check the number of features expected by the model\n",
        "print(f\"Model expects {model.n_features_in_} features.\")\n",
        "\n",
        "# Extract features from the URL\n",
        "url_features = extract_features(url)\n",
        "\n",
        "# Check the number of features extracted\n",
        "print(f\"Extracted {url_features.shape[1]} features.\")\n",
        "\n",
        "# Predict using the model\n",
        "prediction = model.predict(url_features)\n",
        "\n",
        "# Output result\n",
        "if prediction == 1:\n",
        "    print(f\"The URL '{url}' is predicted as **Phishy**.\")\n",
        "else:\n",
        "    print(f\"The URL '{url}' is predicted as **Legitimate**.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmkr92EPjIX-"
      },
      "source": [
        "Org Flow Contd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z7zzIipUoGc"
      },
      "source": [
        "# Random Forest suits well with 96% accuracy, Now we will check if any other model suits more accurateky with the models or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0b8GMgAVICm",
        "outputId": "43302636-8416-42e8-88e6-12d3997b6859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Logistic Regression...\n",
            "\n",
            "Accuracy for Logistic Regression: 0.7898022892819979\n",
            "\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.88      0.82     13177\n",
            "           1       0.82      0.68      0.75     10848\n",
            "\n",
            "    accuracy                           0.79     24025\n",
            "   macro avg       0.80      0.78      0.78     24025\n",
            "weighted avg       0.79      0.79      0.79     24025\n",
            "\n",
            "\n",
            "Confusion Matrix for Logistic Regression:\n",
            "[[11570  1607]\n",
            " [ 3443  7405]]\n",
            "\n",
            "============================================================\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Accuracy for SVM: 0.8367533818938606\n",
            "\n",
            "Classification Report for SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86     13177\n",
            "           1       0.86      0.76      0.81     10848\n",
            "\n",
            "    accuracy                           0.84     24025\n",
            "   macro avg       0.84      0.83      0.83     24025\n",
            "weighted avg       0.84      0.84      0.84     24025\n",
            "\n",
            "\n",
            "Confusion Matrix for SVM:\n",
            "[[11817  1360]\n",
            " [ 2562  8286]]\n",
            "\n",
            "============================================================\n",
            "\n",
            "Training KNN...\n",
            "\n",
            "Accuracy for KNN: 0.8768366285119668\n",
            "\n",
            "Classification Report for KNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89     13177\n",
            "           1       0.89      0.83      0.86     10848\n",
            "\n",
            "    accuracy                           0.88     24025\n",
            "   macro avg       0.88      0.87      0.87     24025\n",
            "weighted avg       0.88      0.88      0.88     24025\n",
            "\n",
            "\n",
            "Confusion Matrix for KNN:\n",
            "[[12036  1141]\n",
            " [ 1818  9030]]\n",
            "\n",
            "============================================================\n",
            "\n",
            "Training Gradient Boosting...\n",
            "\n",
            "Accuracy for Gradient Boosting: 0.8526951092611863\n",
            "\n",
            "Classification Report for Gradient Boosting:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87     13177\n",
            "           1       0.87      0.79      0.83     10848\n",
            "\n",
            "    accuracy                           0.85     24025\n",
            "   macro avg       0.86      0.85      0.85     24025\n",
            "weighted avg       0.85      0.85      0.85     24025\n",
            "\n",
            "\n",
            "Confusion Matrix for Gradient Boosting:\n",
            "[[11929  1248]\n",
            " [ 2291  8557]]\n",
            "\n",
            "============================================================\n",
            "\n",
            "Training AdaBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy for AdaBoost: 0.8328824141519251\n",
            "\n",
            "Classification Report for AdaBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85     13177\n",
            "           1       0.85      0.76      0.80     10848\n",
            "\n",
            "    accuracy                           0.83     24025\n",
            "   macro avg       0.84      0.83      0.83     24025\n",
            "weighted avg       0.83      0.83      0.83     24025\n",
            "\n",
            "\n",
            "Confusion Matrix for AdaBoost:\n",
            "[[11723  1454]\n",
            " [ 2561  8287]]\n",
            "\n",
            "============================================================\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Accuracy for XGBoost: 0.8896566077003122\n",
            "\n",
            "Classification Report for XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90     13177\n",
            "           1       0.90      0.84      0.87     10848\n",
            "\n",
            "    accuracy                           0.89     24025\n",
            "   macro avg       0.89      0.89      0.89     24025\n",
            "weighted avg       0.89      0.89      0.89     24025\n",
            "\n",
            "\n",
            "Confusion Matrix for XGBoost:\n",
            "[[12213   964]\n",
            " [ 1687  9161]]\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# List of models to test\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': xgb.XGBClassifier()\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nAccuracy for {model_name}: {accuracy}\")\n",
        "\n",
        "    # Display the classification report\n",
        "    print(f\"\\nClassification Report for {model_name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Display the confusion matrix\n",
        "    print(f\"\\nConfusion Matrix for {model_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}